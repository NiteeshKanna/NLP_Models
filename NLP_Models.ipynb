{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606493a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183e753",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28e7246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -----------------------Bernoulli-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       994\n",
      "           1       1.00      0.97      0.99       936\n",
      "\n",
      "    accuracy                           0.99      1930\n",
      "   macro avg       0.99      0.99      0.99      1930\n",
      "weighted avg       0.99      0.99      0.99      1930\n",
      "\n",
      "    -----------------------Multinomial-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       961\n",
      "           1       0.99      0.97      0.98       969\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "Time Taken 10 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "df=pd.read_csv(\"spam.csv\")\n",
    "\n",
    "count_0,count_1 = df[\"Category\"].value_counts()\n",
    "df_0 = df[df[\"Category\"] == \"ham\"]\n",
    "df_1 = df[df[\"Category\"] == \"spam\"]\n",
    "\n",
    "df_1_over= df_1.sample(count_0,replace = True)\n",
    "df = pd.concat([df_0,df_1_over],axis=0)\n",
    "\n",
    "df[\"Category\"] = df[\"Category\"].apply(lambda x : 0 if x == \"ham\" else 1)\n",
    "df.dropna(inplace=True,axis=1)\n",
    "col=df.select_dtypes(include=\"object\").columns \n",
    "cv=CountVectorizer()\n",
    "for i in col:\n",
    "    cols=cv.fit_transform(df[i])\n",
    "    arr=cols.toarray() \n",
    "    column_name = list(map(lambda x : f\"{i}-{x}\",cv.get_feature_names_out()))\n",
    "    data=pd.DataFrame(arr,columns = column_name)\n",
    "    df = df.drop(i,axis = 1)\n",
    "    df.reset_index(inplace = True)\n",
    "    df=pd.concat([df,data],axis=1)\n",
    "df.head()\n",
    "\n",
    "X = df.drop(\"Category\",axis=1)\n",
    "y = df[\"Category\"]\n",
    "\n",
    "print(\"    -----------------------Bernoulli-------------------\\n\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf =  BernoulliNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"    -----------------------Multinomial-------------------\\n\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf =  MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time Taken {round(end - start)} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b441b98",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "795f44ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -----------------------Bernoulli-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       947\n",
      "           1       1.00      0.97      0.98       983\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "    -----------------------Multinomial-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       939\n",
      "           1       0.99      0.98      0.99       991\n",
      "\n",
      "    accuracy                           0.99      1930\n",
      "   macro avg       0.99      0.99      0.99      1930\n",
      "weighted avg       0.99      0.99      0.99      1930\n",
      "\n",
      "Time Taken 8 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "df=pd.read_csv(\"spam.csv\")\n",
    "\n",
    "count_0,count_1 = df[\"Category\"].value_counts()\n",
    "df_0 = df[df[\"Category\"] == \"ham\"]\n",
    "df_1 = df[df[\"Category\"] == \"spam\"]\n",
    "\n",
    "df_1_over= df_1.sample(count_0,replace = True)\n",
    "df = pd.concat([df_0,df_1_over],axis=0)\n",
    "\n",
    "df[\"Category\"] = df[\"Category\"].apply(lambda x : 0 if x == \"ham\" else 1)\n",
    "df.dropna(inplace=True,axis=1)\n",
    "col=df.select_dtypes(include=\"object\").columns \n",
    "cv=TfidfVectorizer()\n",
    "for i in col:\n",
    "    cols=cv.fit_transform(df[i])\n",
    "    arr=cols.toarray() \n",
    "    column_name = list(map(lambda x : f\"{i}-{x}\",cv.get_feature_names_out()))\n",
    "    data=pd.DataFrame(arr,columns = column_name)\n",
    "    df = df.drop(i,axis = 1)\n",
    "    df.reset_index(inplace = True)\n",
    "    df=pd.concat([df,data],axis=1)\n",
    "df.head()\n",
    "\n",
    "X = df.drop(\"Category\",axis=1)\n",
    "y = df[\"Category\"]\n",
    "\n",
    "print(\"    -----------------------Bernoulli-------------------\\n\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf =  BernoulliNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"    -----------------------Multinomial-------------------\\n\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf =  MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time Taken {round(end - start)} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71b72d",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe54fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken 91 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import gensim.downloader as api\n",
    "word = api.load(\"word2vec-google-news-300\")\n",
    "end = time.time()\n",
    "print(f\"Time Taken {round(end - start)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f61f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -----------------------Bernoulli-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1580\n",
      "           1       0.00      0.00      0.00      1586\n",
      "\n",
      "    accuracy                           0.50      3166\n",
      "   macro avg       0.25      0.50      0.33      3166\n",
      "weighted avg       0.25      0.50      0.33      3166\n",
      "\n",
      "    -----------------------Multinomial-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85      1580\n",
      "           1       0.95      0.70      0.81      1586\n",
      "\n",
      "    accuracy                           0.83      3166\n",
      "   macro avg       0.86      0.83      0.83      3166\n",
      "weighted avg       0.86      0.83      0.83      3166\n",
      "\n",
      "Time Taken 1 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "def preprocessing(text):\n",
    "    doc = text.split()\n",
    "    vector = [word[token] for token in doc if token in word]\n",
    "    return np.mean(vector,axis=0)\n",
    "\n",
    "df=pd.read_csv(\"spam.csv\")\n",
    "\n",
    "count_0,count_1 = df[\"Category\"].value_counts()\n",
    "df_0 = df[df[\"Category\"] == \"ham\"]\n",
    "df_1 = df[df[\"Category\"] == \"spam\"]\n",
    "\n",
    "df_1_over= df_1.sample(count_0,replace = True)\n",
    "df = pd.concat([df_0,df_1_over],axis=0)\n",
    "\n",
    "sep = list(map(lambda x: (x, df[x].fillna(df[x].mode()[0], inplace = True)), df.columns))\n",
    "\n",
    "df[\"Category\"] = df[\"Category\"].apply(lambda x : 0 if x == \"ham\" else 1)\n",
    "\n",
    "col=df.select_dtypes(include=\"object\").columns \n",
    "\n",
    "for i in col:\n",
    "    df[i] = df[i].apply(preprocessing)\n",
    "df.dropna(inplace=True)\n",
    "X = np.stack(df[\"Message\"].values)\n",
    "y = df[\"Category\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_train = scaler.fit_transform(X_train)\n",
    "scaler_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"    -----------------------Bernoulli-------------------\\n\")\n",
    "clf =  BernoulliNB()\n",
    "clf.fit(scaler_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"    -----------------------Multinomial-------------------\\n\")\n",
    "clf =  MultinomialNB()\n",
    "clf.fit(scaler_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time Taken {round(end - start)} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc54ee",
   "metadata": {},
   "source": [
    "### GLove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5b567fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -----------------------Bernoulli-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1593\n",
      "           1       0.00      0.00      0.00      1592\n",
      "\n",
      "    accuracy                           0.50      3185\n",
      "   macro avg       0.25      0.50      0.33      3185\n",
      "weighted avg       0.25      0.50      0.33      3185\n",
      "\n",
      "    -----------------------Multinomial-------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85      1593\n",
      "           1       0.82      0.93      0.87      1592\n",
      "\n",
      "    accuracy                           0.86      3185\n",
      "   macro avg       0.87      0.86      0.86      3185\n",
      "weighted avg       0.87      0.86      0.86      3185\n",
      "\n",
      "Time Taken 122 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df = pd.read_csv(\"spam.csv\")\n",
    "count_0,count_1 = df[\"Category\"].value_counts()\n",
    "df_0 = df[df[\"Category\"] == \"ham\"]\n",
    "df_1 = df[df[\"Category\"] == \"spam\"]\n",
    "\n",
    "df_1_over= df_1.sample(count_0,replace = True)\n",
    "df = pd.concat([df_0,df_1_over],axis=0)\n",
    "\n",
    "df[\"Category\"] = df[\"Category\"].apply(lambda x : 0 if x == \"ham\" else 1)\n",
    "\n",
    "df[\"Message\"] = df[\"Message\"].apply(lambda x : nlp(x).vector)\n",
    "\n",
    "X = np.stack(df[\"Message\"])\n",
    "y = np.stack(df[\"Category\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=0.33, \n",
    "    random_state=42,stratify=y)\n",
    "scaler = MinMaxScaler()\n",
    "scaler_train = scaler.fit_transform(X_train)\n",
    "scaler_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"    -----------------------Bernoulli-------------------\\n\")\n",
    "\n",
    "clf =  BernoulliNB()\n",
    "clf.fit(scaler_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"    -----------------------Multinomial-------------------\\n\")\n",
    "clf = MultinomialNB()\n",
    "clf.fit(scaler_train,y_train)\n",
    "y_pred = clf.predict(scaler_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time Taken {round(end - start)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a419cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df = df.head(10000)\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x : 0 if x == \"negative\" else 1)\n",
    "df.dropna(inplace=True,axis=1)\n",
    "col=df.select_dtypes(include=\"object\").columns \n",
    "cv=TfidfVectorizer()\n",
    "for i in col:\n",
    "    cols=cv.fit_transform(df[i])\n",
    "    arr=cols.toarray() \n",
    "    column_name = list(map(lambda x : f\"{i}-{x}\",cv.get_feature_names_out()))\n",
    "    data=pd.DataFrame(arr,columns = column_name)\n",
    "    df = df.drop(i,axis = 1)\n",
    "    df.reset_index(inplace = True)\n",
    "    df=pd.concat([df,data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98031d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"IMDB Numeric dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb2590c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review-00</th>\n",
       "      <th>review-000</th>\n",
       "      <th>review-00001</th>\n",
       "      <th>review-0069</th>\n",
       "      <th>review-007</th>\n",
       "      <th>review-00am</th>\n",
       "      <th>review-00s</th>\n",
       "      <th>review-01</th>\n",
       "      <th>...</th>\n",
       "      <th>review-être</th>\n",
       "      <th>review-ís</th>\n",
       "      <th>review-ísnt</th>\n",
       "      <th>review-île</th>\n",
       "      <th>review-ïn</th>\n",
       "      <th>review-óli</th>\n",
       "      <th>review-önsjön</th>\n",
       "      <th>review-über</th>\n",
       "      <th>review-überwoman</th>\n",
       "      <th>review-ünfaithful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 52642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  sentiment  review-00  review-000  review-00001  review-0069  \\\n",
       "0         0          1        0.0         0.0           0.0          0.0   \n",
       "1         1          1        0.0         0.0           0.0          0.0   \n",
       "2         2          1        0.0         0.0           0.0          0.0   \n",
       "3         3          0        0.0         0.0           0.0          0.0   \n",
       "4         4          1        0.0         0.0           0.0          0.0   \n",
       "...     ...        ...        ...         ...           ...          ...   \n",
       "9995   9995          1        0.0         0.0           0.0          0.0   \n",
       "9996   9996          0        0.0         0.0           0.0          0.0   \n",
       "9997   9997          0        0.0         0.0           0.0          0.0   \n",
       "9998   9998          0        0.0         0.0           0.0          0.0   \n",
       "9999   9999          1        0.0         0.0           0.0          0.0   \n",
       "\n",
       "      review-007  review-00am  review-00s  review-01  ...  review-être  \\\n",
       "0            0.0          0.0         0.0        0.0  ...          0.0   \n",
       "1            0.0          0.0         0.0        0.0  ...          0.0   \n",
       "2            0.0          0.0         0.0        0.0  ...          0.0   \n",
       "3            0.0          0.0         0.0        0.0  ...          0.0   \n",
       "4            0.0          0.0         0.0        0.0  ...          0.0   \n",
       "...          ...          ...         ...        ...  ...          ...   \n",
       "9995         0.0          0.0         0.0        0.0  ...          0.0   \n",
       "9996         0.0          0.0         0.0        0.0  ...          0.0   \n",
       "9997         0.0          0.0         0.0        0.0  ...          0.0   \n",
       "9998         0.0          0.0         0.0        0.0  ...          0.0   \n",
       "9999         0.0          0.0         0.0        0.0  ...          0.0   \n",
       "\n",
       "      review-ís  review-ísnt  review-île  review-ïn  review-óli  \\\n",
       "0           0.0          0.0         0.0        0.0         0.0   \n",
       "1           0.0          0.0         0.0        0.0         0.0   \n",
       "2           0.0          0.0         0.0        0.0         0.0   \n",
       "3           0.0          0.0         0.0        0.0         0.0   \n",
       "4           0.0          0.0         0.0        0.0         0.0   \n",
       "...         ...          ...         ...        ...         ...   \n",
       "9995        0.0          0.0         0.0        0.0         0.0   \n",
       "9996        0.0          0.0         0.0        0.0         0.0   \n",
       "9997        0.0          0.0         0.0        0.0         0.0   \n",
       "9998        0.0          0.0         0.0        0.0         0.0   \n",
       "9999        0.0          0.0         0.0        0.0         0.0   \n",
       "\n",
       "      review-önsjön  review-über  review-überwoman  review-ünfaithful  \n",
       "0               0.0          0.0               0.0                0.0  \n",
       "1               0.0          0.0               0.0                0.0  \n",
       "2               0.0          0.0               0.0                0.0  \n",
       "3               0.0          0.0               0.0                0.0  \n",
       "4               0.0          0.0               0.0                0.0  \n",
       "...             ...          ...               ...                ...  \n",
       "9995            0.0          0.0               0.0                0.0  \n",
       "9996            0.0          0.0               0.0                0.0  \n",
       "9997            0.0          0.0               0.0                0.0  \n",
       "9998            0.0          0.0               0.0                0.0  \n",
       "9999            0.0          0.0               0.0                0.0  \n",
       "\n",
       "[10000 rows x 52642 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e464ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
